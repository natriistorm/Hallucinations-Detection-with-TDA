{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pou1UJzQhxJt"
      },
      "source": [
        "# Ваш первый классификатор\n",
        "\n",
        "Напоминание: $X$ - набор объектов, с признаками\n",
        "$Y$ - набор правильных ответов для каждого объекта\n",
        "\n",
        "Цель - построить алгоритм $a(X)$ предсказать для каждого обхекта $X$ правильный ответ с\n",
        "\n",
        "$$y = a([x_1, x_2, x_3, ...])$$\n",
        "\n",
        "\n",
        "Простейшая задача классификации - бинарная классификация, где ответом для каждого объекта будет 0 или 1, \"True\" или \"False\"; \"Да\" или \"Нет\", \"Вернет кредит\" или \"Не вернет кредит\"; и тд"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciOk7Jk3hxJw"
      },
      "source": [
        "В этом упражнении мы обучим бинарный классификатор, который будет предсказывать, следует ли пациенту пройти обследование на диабет, основываясь на некоторых медицинских данных.\n",
        "\n",
        "\n",
        "### Загрузка и исследование данных\n",
        "\n",
        "Загрузите из репозитория файл diabetes.csv и загрузите его сюда, нажав слева на ячейку с папкой\n",
        "Выполните следующую ячейку, чтобы загрузить CSV-файл с данными о пациентах в датафрейм **Pandas**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "oddmh4y-hxJw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "diabetes = pd.read_csv('diabetes.csv')\n",
        "diabetes.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpxTOpHwhxJx"
      },
      "source": [
        "Эти данные состоят из диагностической информации о некоторых пациентах, которые прошли тест на диабет. При необходимости прокрутите страницу вправо и обратите внимание, что последний столбец набора данных (**Diabetic**) содержит значение ***0*** для пациентов с отрицательным тестом на диабет и ***1*** для пациентов с положительным тестом. Это та метка, которую мы будем обучать нашу модель предсказывать; большинство других столбцов\n",
        "\n",
        " (**Беременность**, **Уровень глюкозы**, **Давление** и так далее) - это признаки, которые мы будем использовать для предсказания метки **Diabetic**.\n",
        "\n",
        "Давайте отделим признаки от меток - назовем признаки ***X***, а метку ***y***:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "TT7Dk0PvhxJx"
      },
      "outputs": [],
      "source": [
        "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
        "label = 'Diabetic'\n",
        "X, y = diabetes[features].values, diabetes[label].values\n",
        "\n",
        "for n in range(0,4):\n",
        "    print(\"Patient\", str(n+1), \"\\n  Features:\",list(X[n]), \"\\n  Label:\", y[n])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGbD4AMhhxJy"
      },
      "source": [
        "Теперь давайте сравним распределения признаков для каждого значения метки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "ZRDkiuuhhxJy"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "features = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']\n",
        "for col in features:\n",
        "    diabetes.boxplot(column=col, by='Diabetic', figsize=(6,6))\n",
        "    plt.title(col)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQJw0RrlhxJy"
      },
      "source": [
        "Для некоторых характеристик наблюдается заметная разница в распределении для каждого значения метки. В частности, для признаков «Беременность» и «Возраст» распределения для пациентов с диабетом заметно отличаются от распределений для пациентов без диабета. Эти признаки могут помочь предсказать, является ли пациент диабетиком или нет.\n",
        "\n",
        "### Разделим наши данные\n",
        "\n",
        "Наш набор данных содержит известные значения метки, поэтому мы можем использовать его для обучения классификатора, чтобы он находил статистическую связь между признаками и значением метки; но как мы узнаем, хороша ли наша модель? Как мы узнаем, что она будет предсказывать правильно, если мы используем ее с новыми данными, на которых она не обучалась? Мы можем воспользоваться тем, что у нас есть большой набор данных с известными значениями меток, использовать только часть из них для обучения модели и отложить часть для тестирования обученной модели - это позволит нам сравнить предсказанные метки с уже известными метками в тестовом наборе.\n",
        "\n",
        "В Python пакет **scikit-learn** содержит большое количество функций, которые мы можем использовать для построения модели машинного обучения, включая функцию **train_test_split**, которая обеспечивает случайное разделение данных для обучения и тестирования. С ее помощью мы разделим данные на 70 % для обучения и 30 % для тестирования."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "afYa_ya5hxJy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.30,\n",
        "                                                    random_state=0)\n",
        "\n",
        "print ('Training cases: %d\\nTest cases: %d' % (X_train.shape[0], X_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhgYK3UJhxJz"
      },
      "source": [
        "### Обучим нашу первую модель!\n",
        "\n",
        "\n",
        "Итак, теперь мы готовы обучить нашу модель, подогнав обучающие признаки (**X_train**) к обучающим меткам (**y_train**). Существуют различные алгоритмы, которые мы можем использовать для обучения модели. В этом примере мы будем использовать *Логистическую регрессию*, которая является хорошо зарекомендовавшим себя алгоритмом классификации.\n",
        "\n",
        "> **Примечание**: Параметры алгоритмов машинного обучения обычно называются *гиперпараметрами* (для специалиста по изучению данных *параметры* - это значения в самих данных, а *гиперпараметры* определяются извне, на основе данных)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "-tO8vIwGhxJz"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "reg = 0.01\n",
        "# C=1/reg, solver=\"liblinear\" - гиперпараметры здесь\n",
        "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6sVih5PhxJz"
      },
      "source": [
        "Теперь, когда мы обучили модель на обучающих данных, мы можем использовать тестовые данные, которые мы отложили, чтобы оценить, насколько хорошо она предсказывает. В этом нам снова поможет **scikit-learn**. Давайте начнем с использования модели для предсказания меток для нашего тестового набора и сравним предсказанные метки с известными метками:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "qmo3wQwahxJz"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "print('Предсказания: ', predictions)\n",
        "print('Истинные ответы:    ' ,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8vORII1hxJ0"
      },
      "source": [
        "Массивы меток слишком длинные, чтобы выводить их в блокноте, поэтому мы можем сравнить только несколько значений. Даже если бы мы распечатали все предсказанные и фактические метки, их было бы слишком много, чтобы это было разумным способом оценки модели. К счастью, у **scikit-learn** есть для этого функции, и библиотека предоставляет некоторые метрики, которые мы можем использовать для оценки модели.\n",
        "\n",
        "Самое очевидное, что вы можете захотеть сделать, это проверить *accuracy* предсказаний - простыми словами, какую долю меток модель предсказала правильно?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "kR3pVfo6hxJ0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Accuracy: ', accuracy_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPtbk98whxJ0"
      },
      "source": [
        "Точность возвращается в виде десятичного значения - значение 1.0 означает, что модель сделала 100 % правильных предсказаний; в то время как точность 0.0, ну, довольно бесполезна!\n",
        "\n",
        "Точность кажется разумной метрикой для оценки (и в некоторой степени так оно и есть), но нужно быть осторожным и не делать слишком много выводов из точности классификатора. Помните, что это просто показатель того, сколько случаев было предсказано правильно. Предположим, только 3 % населения страдают диабетом. Можно создать классификатор, который всегда предсказывает только 0, и он будет точным на 97 %, но не слишком полезным для выявления пациентов с диабетом!\n",
        "\n",
        "К счастью, есть и другие метрики, которые позволяют узнать немного больше о том, как работает наша модель. В Scikit-Learn есть возможность создать *отчет о классификации*, который дает больше информации, чем только сырая точность."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "8BQB_vH_hxJ0"
      },
      "outputs": [],
      "source": [
        "from sklearn. metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y37IvZxrhxJ0"
      },
      "source": [
        "Отчет о классификации включает следующие метрики для каждого класса (0 и 1)\n",
        "\n",
        "> обратите внимание, что строка заголовка может не совпадать со значениями!\n",
        "\n",
        "* * *Precision*: Какая часть предсказаний, сделанных моделью для этого класса, оказалась верной?\n",
        "* *Recall*: Из всех экземпляров этого класса в тестовом наборе данных, какую часть идентифицировала модель?\n",
        "* *F1-Score*: Средняя метрика, учитывающая precision и recall.\n",
        "* *Support*: Сколько экземпляров этого класса имеется в тестовом наборе данных?\n",
        "\n",
        "Отчет о классификации также включает средние показатели для этих метрик, в том числе средневзвешенное значение, которое позволяет учесть дисбаланс в количестве случаев каждого класса.\n",
        "\n",
        "Поскольку это *бинарная* задача классификации, класс ***1*** считается *позитивным*, и его точность и отзыв представляют особый интерес - они фактически отвечают на вопросы:\n",
        "\n",
        "- Из всех пациентов, которым модель предсказала диабет, сколько на самом деле являются диабетиками?\n",
        "- Сколько из всех пациентов, которые на самом деле являются диабетиками, было выявлено моделью?\n",
        "\n",
        "Вы можете получить эти значения самостоятельно, используя метрики **precision_score** и **recall_score** в scikit-learn (которые по умолчанию предполагают бинарную модель классификации)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "rKkiNHBVhxJ0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(\"Общий Precision:\",precision_score(y_test, predictions))\n",
        "print(\"Общий Recall:\",recall_score(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0925mPThxJ1"
      },
      "source": [
        "Показатели precision и recall определяются на основе четырех возможных результатов прогнозирования:\n",
        "* * Истинные положительные результаты (True Positive): Предсказанная метка и фактическая метка равны 1.\n",
        "* * Ложные положительные результаты* (False Positive): Предсказанная метка равна 1, но фактическая метка равна 0.\n",
        "* *Ложные отрицательные* (False Negative): Предсказанная метка равна 0, а фактическая - 1.\n",
        "* * Истинные отрицательные значения* (True Negative): Предсказанная метка и фактическая метка равны 0.\n",
        "\n",
        "Эти метрики обычно собираются в таблицу для тестового набора данных и отображаются вместе в виде *матрицы ошибок*, которая имеет следующий вид:\n",
        "\n",
        "<table style=\"border: 1px solid black;\">\n",
        "    <tr style=\"border: 1px solid black;\">\n",
        "        <td style=\"border: 1px solid black;color: black;\" bgcolor=\"lightgray\">TN</td><td style=\"border: 1px solid black;color: black;\" bgcolor=\"white\">FP</td>\n",
        "    </tr>\n",
        "    <tr style=\"border: 1px solid black;\">\n",
        "        <td style=\"border: 1px solid black;color: black;\" bgcolor=\"white\">FN</td><td style=\"border: 1px solid black;color: black;\" bgcolor=\"lightgray\">TP</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "Обратите внимание, что правильные (*истинные*) предсказания образуют диагональную линию сверху слева направо - эти цифры должны быть значительно выше, чем *ложные* предсказания, если модель хоть сколько-нибудь хороша.\n",
        "\n",
        "В Python вы можете использовать функцию **sklearn.metrics.confusion_matrix**, чтобы найти эти значения для обученного классификатора:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "9pXRBAX8hxJ1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print (cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtpDpT4RhxJ1"
      },
      "source": [
        "До сих пор мы рассматривали предсказания модели как метки классов 1 или 0. На самом деле все немного сложнее. Статистические алгоритмы машинного обучения, такие как логистическая регрессия, основаны на *вероятности*; поэтому то, что на самом деле предсказывает бинарный классификатор, - это вероятность того, что метка является истинной (**P(y)**), и вероятность того, что метка является ложной (1 - **P(y)**). Пороговое значение 0,5 используется для определения того, является ли предсказанная метка 1 (если *P(y) > 0,5*) или 0 (если *P(y) <= 0,5*). Вы можете использовать метод **predict_proba**, чтобы увидеть пары вероятностей для каждого случая:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "TioE9s50hxJ1"
      },
      "outputs": [],
      "source": [
        "y_scores = model.predict_proba(X_test)\n",
        "print(y_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkWe9Q-zhxJ2"
      },
      "source": [
        "Решение о том, считать ли предсказание 1 или 0, зависит от порогового значения, с которым сравниваются предсказанные вероятности. Если мы изменим порог, это повлияет на предсказания и все 4 значения (TP, TN, FP, FN), а значит, изменит метрики в матрице ошибок. Обычный способ оценки классификатора заключается в изучении *коэффициента истинных положительных результатов* (True Positive Rate) и *коэффициента ложных положительных результатов* (False Positive Rate) для ряда возможных порогов.\n",
        "\n",
        "Формулы, по которым считаются эти две величины:\n",
        "\n",
        "\n",
        "$$ FPR = \\frac{FP}{FP + TN} $$\n",
        "\n",
        "$$ TPR = \\frac{TP}{FN + TP} $$\n",
        "\n",
        "ничего формула TPR не напоминает?\n",
        "\n",
        "Затем эти показатели строятся по всем возможным пороговым значениям, чтобы сформировать график, известный как ROC, как показано ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9MeC2gKhxJ2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0Fuf1dZhxJ2"
      },
      "source": [
        "График ROC показывает кривую истинных и ложных положительных результатов для различных пороговых значений от 0 до 1. Идеальный классификатор будет иметь кривую, которая идет прямо вверх по левой стороне и прямо через верх. Диагональная линия, пересекающая график, представляет собой вероятность правильного предсказания при случайном прогнозе 50/50; поэтому очевидно, что кривая должна быть выше этого значения (иначе ваша модель не лучше простого угадывания!).\n",
        "\n",
        "Площадь под кривой (AUC - Area Under Curve) - это значение от 0 до 1, которое оценивает общую эффективность модели. Чем ближе к 1 это значение, тем лучше модель. И снова, scikit-learn включает функцию для расчета этой метрики."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "njJgtAXwhxJ2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Upr5UbKihxJ2"
      },
      "source": [
        "### Выполните предварительную обработку в конвейере\n",
        "\n",
        "В данном случае ROC-кривая и ее AUC показывают, что модель работает лучше, чем случайное предположение, что неплохо, учитывая, что мы выполнили очень мало предварительной обработки данных.\n",
        "\n",
        "На практике обычно выполняется некоторая предварительная обработка данных, чтобы алгоритму было проще подобрать к ним модель. Существует огромное количество преобразований, которые можно выполнить, чтобы подготовить данные к моделированию, но мы ограничимся несколькими распространенными методами:\n",
        "\n",
        "- Нормализация (масштабирование) числовых признаков, чтобы они находились в одном масштабе. Это не позволит признакам с большими значениями заставлять модель подбирать коэффициенты, непропорционально влияющие на прогнозы.\n",
        "\n",
        "\n",
        "- Кодирование категориальных переменных. Например, используя технику *one-hot-encoding*, можно создавать отдельные бинарные признаки (истина/ложь) для каждого возможного значения категории.\n",
        "\n",
        "Для применения этих предварительных преобразований мы воспользуемся функцией Scikit-Learn под названием *pipelines*. Она позволяют определить набор шагов предварительной обработки, которые завершаются алгоритмом. Затем вы можете запустить весь этого процесс на данным, так что модель будет включать в себя все шаги предварительной обработки, а также непосредственно алгоритм классификации. Это полезно, поскольку, когда мы захотим использовать модель для предсказания значений по новым данным, нам нужно будет применить те же преобразования, что были применены к обучающим данным (понимаете, почему?)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "pCj4cEzOhxJ2"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# запускаем нормализацию численных признаков - для этого указали их индексы\n",
        "numeric_features = [0,1,2,3,4,5,6]\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())])\n",
        "\n",
        "# определеим, что делаем с категориальным признаком - возраст\n",
        "categorical_features = [7]\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
        "\n",
        "# объединяем два предыдущих шага\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)])\n",
        "\n",
        "# Создаем пайплайн предобработки и обучения\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('logregressor', LogisticRegression(C=1/reg, solver=\"liblinear\"))])\n",
        "\n",
        "\n",
        "# Запускаем его на обучающих данных\n",
        "model = pipeline.fit(X_train, (y_train))\n",
        "print (model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Ng5RF6kXhxJ3"
      },
      "outputs": [],
      "source": [
        "# Получаем предсказания для тестовой выборки\n",
        "predictions = model.predict(X_test)\n",
        "y_scores = model.predict_proba(X_test)\n",
        "\n",
        "# Подсчитываем метрики чтобы понять, как хорошо справилась модель\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print ('Матрица ошибок:\\n',cm, '\\n')\n",
        "print('Accuracy:', accuracy_score(y_test, predictions))\n",
        "print(\"Общий Precision:\",precision_score(y_test, predictions))\n",
        "print(\"Общий Recall:\",recall_score(y_test, predictions))\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "\n",
        "# ROC-кривая\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8kXGUf1hxJ3"
      },
      "source": [
        "Результаты выглядят немного лучше, так что очевидно, что предварительная обработка данных имеет значение.\n",
        "\n",
        "### Попробуйте другой алгоритм\n",
        "\n",
        "Теперь давайте попробуем другой алгоритм. Ранее мы использовали алгоритм логистической регрессии, который является *линейным* алгоритмом. Существует множество видов алгоритмов классификации, которые мы могли бы попробовать, включая:\n",
        "\n",
        "\n",
        "- **Support Vector Machine algorithms**\n",
        "- **Tree-based algorithms**\n",
        "- **Ensemble algorithms**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "VQ_tboduhxJ4"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('logregressor', RandomForestClassifier(n_estimators=100))])\n",
        "\n",
        "model = pipeline.fit(X_train, (y_train))\n",
        "print (model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "8mCSfl6UhxJ5"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "y_scores = model.predict_proba(X_test)\n",
        "cm = confusion_matrix(y_test, predictions)\n",
        "print ('Матрица ошибок:\\n',cm, '\\n')\n",
        "print('Accuracy:', accuracy_score(y_test, predictions))\n",
        "print(\"Общий Precision:\",precision_score(y_test, predictions))\n",
        "print(\"Общий Recall:\",recall_score(y_test, predictions))\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('\\nAUC: ' + str(auc))\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQZYEcnyhxJ5"
      },
      "source": [
        "\n",
        "### Использование моделей для предсказаний"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWqTjYexhxJ5"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import os\n",
        "\n",
        "# Сохраняем модель для дальнейшего использования\n",
        "os.mkdir('models')\n",
        "filename = './models/diabetes_model.pkl'\n",
        "joblib.dump(model, filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owegzzV5hxJ5"
      },
      "source": [
        "When we have some new observations for which the label is unknown, we can load the model and use it to predict values for the unknown label:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "HrC2VKeUhxJ5"
      },
      "outputs": [],
      "source": [
        "# Загружаем модель\n",
        "model = joblib.load(filename)\n",
        "\n",
        "# создадим данные нового пациента\n",
        "X_new = np.array([[2,180,74,24,21,23.9091702,1.488172308,22]])\n",
        "print ('Пациент: {}'.format(list(X_new[0])))\n",
        "\n",
        "pred = model.predict(X_new)\n",
        "\n",
        "print('Предсказанный ответ - {}'.format(pred[0]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6 - AzureML",
      "language": "python",
      "name": "python3-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}